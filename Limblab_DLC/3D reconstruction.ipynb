{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jul 25 14:31:01 2019\n",
    "@author: minyoungpark\n",
    "\n",
    "Moved to Jupyter notebook (for better or worse) on 12/03/2020 by Joseph\n",
    "Updated code as well to streamline 3D reconstruction\n",
    "\"\"\"\n",
    "import sys\n",
    "\n",
    "# add folder with calibration functions to path\n",
    "calib_folder = r'D:\\Lab\\GIT\\proc-joe\\Limblab_DLC\\cam_calib_20200508'\n",
    "\n",
    "# set project folder \n",
    "project_folder = r'D:\\Lab\\Data\\DLC_videos\\Han_20201204_rwFreeReach\\Han_reaching-Joe-2020-12-10'\n",
    "\n",
    "# determine if we are using filtered data or not\n",
    "use_filtered_data = True\n",
    "remove_triangulation = False\n",
    "\n",
    "# using reference frame or use an arbitrary frame?\n",
    "use_reference_frame = True\n",
    "\n",
    "# imports and other stuff\n",
    "sys.path.append(calib_folder)\n",
    "\n",
    "from utils.utils import load_config\n",
    "from calibration.intrinsic import calibrate_intrinsic\n",
    "from calibration.extrinsic import calibrate_extrinsic\n",
    "from triangulation.triangulate import reconstruct_3d\n",
    "from utils.vis_utils import generate_three_dim_video\n",
    "from utils.vis_utils import generate_three_dim_pictures\n",
    "from utils.triangulation_utils import add_static_points\n",
    "    \n",
    "import numpy as np\n",
    "import toml\n",
    "import glob\n",
    "import os\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup config file \n",
    "# load basic toml folder and then fill out relevant entries\n",
    "parsed_toml = toml.load(calib_folder + r'\\config_master.toml')\n",
    "\n",
    "# upate calib video path and prefix and extension\n",
    "parsed_toml['calibration']['calib_video_path'] = project_folder + r'\\videos\\calib'\n",
    "parsed_toml['calibration']['calib_video_prefix'] = 'Han_20201204_0000'\n",
    "\n",
    "# set number of camers\n",
    "n_cams = 4\n",
    "\n",
    "\n",
    "# update paths to 2d data while removing (or keeping) videos with filtered\n",
    "if(use_filtered_data):\n",
    "    vid_list = glob.glob(project_folder + r'\\videos\\*filtered.csv')\n",
    "else:\n",
    "    vid_list_temp = glob.glob(project_folder + r'\\videos\\*.csv')\n",
    "    vid_list = []\n",
    "    for vid_name in vid_list_temp:\n",
    "        if vid_name.find('filtered') == -1:\n",
    "            vid_list.append(vid_name)\n",
    "    \n",
    "parsed_toml['paths_to_2d_data'] = vid_list\n",
    "    \n",
    "# update path to save static data\n",
    "parsed_toml['path_to_save_static_data'] = project_folder + r'\\videos'\n",
    "\n",
    "# update output video path\n",
    "parsed_toml['output_video_path'] = project_folder + r'\\reconstructed-3d-data'\n",
    "\n",
    "# update triangulation data (or remove if desired)\n",
    "if(remove_triangulation):\n",
    "    parsed_toml['triangulation'].pop('axes', None)\n",
    "    parsed_toml['triangulation'].pop('reference_point', None)\n",
    "# else, likely leave alone. Could fill this in if we change how we do reference points\n",
    "\n",
    "# update reconstruction output path and threshold\n",
    "parsed_toml['triangulation']['reconstruction_threshold'] = 0.7 # 0.7 default\n",
    "parsed_toml['triangulation']['reconstruction_output_path'] = project_folder + r'\\reconstructed-3d-data'\n",
    "\n",
    "# update labeling scheme and bodyparts interested\n",
    "# only need to update if using something other than base arm points\n",
    "parsed_toml['labeling']['scheme'] = []\n",
    "parsed_toml['labeling']['bodyparts_interested'] = ['shoulder','elbow1','elbow2','wrist1','wrist2','hand1','hand2','hand3','pointX','pointY','pointZ']\n",
    "\n",
    "toml_config_file = project_folder + r'\\recon_config.toml'\n",
    "\n",
    "with open(toml_config_file,'w+') as file:\n",
    "    toml.dump(parsed_toml,file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "intrinsics_1.toml already exists.\n",
      "\n",
      "intrinsics_2.toml already exists.\n",
      "\n",
      "intrinsics_3.toml already exists.\n",
      "\n",
      "intrinsics_4.toml already exists.\n",
      "\n",
      "extrinsics.toml already exists.\n"
     ]
    }
   ],
   "source": [
    "config = load_config(toml_config_file)\n",
    "\n",
    "#%% If you already ran calibration you don't need to run these.\n",
    "calibrate_intrinsic(config)\n",
    "# calibrate intrinsic runs for each camera, so we can run it on the full video list\n",
    "\n",
    "\n",
    "\n",
    "# calibrate extrinsic\n",
    "calibrate_extrinsic(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(use_reference_frame):\n",
    "    labels = ['pointX', 'pointY', 'pointZ']\n",
    "    \n",
    "    snapshots = vid_list\n",
    "\n",
    "    # initialize static\n",
    "    static = {label : [] for label in labels}\n",
    "        \n",
    "    # get labeled reference point for each camera and store in a new file, also copy over other tracking data\n",
    "    # make sure to overwrite pointX, pointY, and pointZ if already exist\n",
    "    # labeled reference point is in each csv file in each folder in project_folder + 'labeled-data'\n",
    "    labeled_folder = project_folder + r'\\labeled-data'\n",
    "    \n",
    "    video_files = config['paths_to_2d_data']\n",
    "    pointX_data = []; pointY_data = []; pointZ_data = [];\n",
    "    \n",
    "    for vid_idx in range(len(video_files)):\n",
    "        video_name = os.path.split(video_files[vid_idx])[-1]\n",
    "        DLC_matches = re.finditer(\"DLC\", video_name)\n",
    "        DLC_idx = [match.start() for match in DLC_matches]\n",
    "        DLC_idx = DLC_idx[-1] # use last one\n",
    "    \n",
    "        video_prefix = video_name[:DLC_idx]\n",
    "    \n",
    "        # only for today's testing session because we are doing 3D reconstruction on different data than we trained the model\n",
    "        video_prefix = video_prefix + \"_trimmed\"\n",
    "        \n",
    "        path_to_folder = labeled_folder + '\\\\' + video_prefix\n",
    "        csv_file = glob.glob(path_to_folder+ '\\\\*.csv')[0]\n",
    "        data = pd.read_csv(csv_file, header=[1,2], index_col=0)\n",
    "    \n",
    "        # get (x,y) for each label Store in Static properly\n",
    "        \n",
    "        for label in labels:\n",
    "            x = data[(label, 'x')].values[~np.isnan(data[(label, 'x')].values)]\n",
    "            y = data[(label, 'y')].values[~np.isnan(data[(label, 'y')].values)]\n",
    "            x = x[0] # only get first labels\n",
    "            y = y[0]\n",
    "            static[label].append([x,y])\n",
    "\n",
    "    \n",
    "    add_static_points(config, labels, static, snapshots)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████| 29492/29492 [00:33<00:00, 881.70it/s]\n"
     ]
    }
   ],
   "source": [
    "if(not os.path.isdir(parsed_toml['triangulation']['reconstruction_output_path'])):\n",
    "    os.mkdir(parsed_toml['triangulation']['reconstruction_output_path'])\n",
    "    \n",
    "recovery = reconstruct_3d(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paths_to_2d_data': ['D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\videos\\\\Han_20201204_00005DLC_resnet50_Han_202012Dec4shuffle1_1030000_filtered.csv',\n",
       "  'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\videos\\\\Han_20201204_00006DLC_resnet50_Han_202012Dec4shuffle1_1030000_filtered.csv',\n",
       "  'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\videos\\\\Han_20201204_00007DLC_resnet50_Han_202012Dec4shuffle1_1030000_filtered.csv',\n",
       "  'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\videos\\\\Han_20201204_00008DLC_resnet50_Han_202012Dec4shuffle1_1030000_filtered.csv'],\n",
       " 'path_to_save_static_data': 'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\videos',\n",
       " 'output_video_path': 'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\reconstructed-3d-data',\n",
       " 'video': {'fps': 25, 'resolution': [1280, 1024]},\n",
       " 'calibration': {'board_type': 'charuco',\n",
       "  'board_size': [5, 7],\n",
       "  'board_marker_bits': 6,\n",
       "  'board_marker_dict_number': 50,\n",
       "  'board_marker_length': 23.17,\n",
       "  'board_square_side_length': 38.43,\n",
       "  'calib_video_path': 'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\videos\\\\calib',\n",
       "  'calib_video_prefix': 'Han_20201204_0000',\n",
       "  'video_extension': 'avi'},\n",
       " 'triangulation': {'cam_align': '1',\n",
       "  'reconstruction_threshold': 0.7,\n",
       "  'reconstruction_output_path': 'D:\\\\Lab\\\\Data\\\\DLC_videos\\\\Han_20201204_rwFreeReach\\\\Han_reaching-Joe-2020-12-10\\\\reconstructed-3d-data',\n",
       "  'optim': False},\n",
       " 'labeling': {'scheme': [],\n",
       "  'bodyparts_interested': ['shoulder',\n",
       "   'elbow1',\n",
       "   'elbow2',\n",
       "   'wrist1',\n",
       "   'wrist2',\n",
       "   'hand1',\n",
       "   'hand2',\n",
       "   'hand3',\n",
       "   'pointX',\n",
       "   'pointY',\n",
       "   'pointZ']},\n",
       " 'filter': {'enabled': False,\n",
       "  'medfilt': 13,\n",
       "  'offset_threshold': 25,\n",
       "  'score_threshold': 0.8,\n",
       "  'spline': True}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# #%% Save 3d recovery json file\n",
    "# import numpy as np\n",
    "# from json import JSONEncoder\n",
    "# import json\n",
    "# class NumpyArrayEncoder(JSONEncoder):\n",
    "#     def default(self, obj):\n",
    "#         if isinstance(obj, np.ndarray):\n",
    "#             return obj.tolist()\n",
    "#         return JSONEncoder.default(self, obj)\n",
    "# with open(\"pop_0610_anipose.json\", \"w\") as write_file:\n",
    "#     json.dump(recovery, write_file, cls=NumpyArrayEncoder)\n",
    "#     \n",
    "# #%% Load 3d recovery json file\n",
    "# import numpy as np\n",
    "# from json import JSONEncoder\n",
    "# import json\n",
    "# with open(\"pop_0317_3.json\", \"r\") as read_file:\n",
    "#     print(\"Converting JSON encoded data into Numpy array\")\n",
    "#     recovery = json.load(read_file)\n",
    "# recovery['registration_mat'] = np.array(recovery['registration_mat'])\n",
    "# recovery['center'] = np.array(recovery['center'])\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "#%% Save 3d recovery json file\n",
    "import numpy as np\n",
    "from json import JSONEncoder\n",
    "import json\n",
    "class NumpyArrayEncoder(JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return JSONEncoder.default(self, obj)\n",
    "with open(\"pop_0610_anipose.json\", \"w\") as write_file:\n",
    "    json.dump(recovery, write_file, cls=NumpyArrayEncoder)\n",
    "#%% Load 3d recovery json file\n",
    "import numpy as np\n",
    "from json import JSONEncoder\n",
    "import json\n",
    "with open(\"pop_0317_3.json\", \"r\") as read_file:\n",
    "    print(\"Converting JSON encoded data into Numpy array\")\n",
    "    recovery = json.load(read_file)\n",
    "recovery['registration_mat'] = np.array(recovery['registration_mat'])\n",
    "recovery['center'] = np.array(recovery['center'])\n",
    "\n",
    "#%% generate 3D picture to find the optimal azimuth and elevation value\n",
    "generate_three_dim_pictures(config)\n",
    "\n",
    "#%% Try 3D stick figure video\n",
    "\n",
    "generate_three_dim_video(config)\n",
    "\n",
    "#%% Testing if the generated 3D results makes sense, by calculating the distance between wrist and hand\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import array as arr\n",
    "\n",
    "data_path = 'C:/Users/dongq/DeepLabCut/Han-Qiwei-2020-02-21/3D-data/output_3d_data_rotate4.csv'\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "wrist = np.empty((len(df), 3))\n",
    "hand = np.empty((len(df), 3))\n",
    "\n",
    "wrist[:,0] = arr(df['wrist1_x'])\n",
    "wrist[:,1] = arr(df['wrist1_y'])\n",
    "wrist[:,2] = arr(df['wrist1_z'])\n",
    "\n",
    "\n",
    "hand[:,0] = arr(df['hand2_x'])\n",
    "hand[:,1] = arr(df['hand2_y'])\n",
    "hand[:,2] = arr(df['hand2_z'])\n",
    "\n",
    "dist = wrist - hand\n",
    "dist_finite = dist[np.isfinite(dist[:,0]), :]\n",
    "dist_3d = np.linalg.norm(dist_finite, axis=1)\n",
    "print(np.median(dist_3d))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
