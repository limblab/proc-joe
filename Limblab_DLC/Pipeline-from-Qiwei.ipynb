{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "On Shrek Docker Only\n",
    "\"\"\"\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from ruamel.yaml import YAML\n",
    "import yaml\n",
    "os.environ[\"DLClight\"]=\"True\"\n",
    "import deeplabcut\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Handle_test_20201201'\n",
    "experimenter = 'Qiwei'\n",
    "video_project_folder = '/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01'\n",
    "path_config_file = video_project_folder + '/config.yaml'\n",
    "linux_config_file = video_project_folder + '/config_linux.yaml'\n",
    "shutil.copyfile(path_config_file,linux_config_file)\n",
    "\n",
    "# convert config file to a linux friendly version\n",
    "with open(path_config_file) as file:\n",
    "    orig_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# change project_path to video_main_folder\n",
    "orig_config['project_path'] = video_project_folder\n",
    "\n",
    "# change video_sets\n",
    "# so we need to build a new dictionary with the video filenames as keys and the crop as entries\n",
    "videos = glob.glob(video_project_folder + r'/videos/*.avi')\n",
    "x=orig_config['video_sets']\n",
    "x_keys = list(x.keys())\n",
    "video_dict = {}\n",
    "for i in range(len(videos)):\n",
    "    video_dict[videos[i]] = x[x_keys[i]]\n",
    "    \n",
    "orig_config['video_sets'] = video_dict\n",
    "\n",
    "# save config as config_linux and point path_config_file to it\n",
    "with open(linux_config_file,'w') as file:\n",
    "    yaml.dump(orig_config,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01/training-datasets/iteration-0/UnaugmentedDataSet_Handle_test_20201201Dec1  already exists!\n",
      "It appears that the images were labeled on a Windows system, but you are currently trying to create a training set on a Unix system. \n",
      " In this case the paths should be converted. Do you want to proceed with the conversion?\n",
      "yes/noyes\n",
      "Annotation data converted to unix format...\n",
      "/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01/dlc-models/iteration-0/Handle_test_20201201Dec1-trainset95shuffle1  already exists!\n",
      "/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01/dlc-models/iteration-0/Handle_test_20201201Dec1-trainset95shuffle1/train  already exists!\n",
      "/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01/dlc-models/iteration-0/Handle_test_20201201Dec1-trainset95shuffle1/test  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 1,  4,  7, 27, 34, 21, 36,  3, 29, 39,  6, 25, 13, 32, 30,  8, 17,\n",
       "          18,  9, 31, 26, 14, 22, 33, 19, 12, 20, 24, 16, 35, 15,  0, 11,  5,\n",
       "          23, 37, 38,  2]), array([10, 28])))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(linux_config_file,userfeedback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0]],\n",
      " 'all_joints_names': ['handle'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Handle_test_20201201Dec1/Handle_test_20201201_Qiwei95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Handle_test_20201201Dec1/Documentation_data-Handle_test_20201201_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01/dlc-models/iteration-0/Handle_test_20201201Dec1-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01/dlc-models/iteration-0/Handle_test_20201201Dec1-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0]], 'all_joints_names': ['handle'], 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Handle_test_20201201Dec1/Handle_test_20201201_Qiwei95shuffle1.mat', 'display_iters': 1000, 'init_weights': '/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Handle_test_20201201Dec1/Documentation_data-Handle_test_20201201_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 1, 'pos_dist_thresh': 17, 'project_path': '/home/jts3256/DLC_videos/Handle_test_20201201-Qiwei-2020-12-01', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[1,77,96,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.001e-05, is_training=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_549 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1054_...ims/concat\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-f4f41de2dea4>\", line 1, in <module>\n    deeplabcut.train_network(linux_config_file)\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 189, in train_network\n    allow_growth=allow_growth,\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\", line 174, in train\n    losses = pose_net(cfg).train(batch)\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py\", line 279, in train\n    heads = self.get_net(batch[Batch.inputs])\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py\", line 178, in get_net\n    net, end_points = self.extract_features(inputs)\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py\", line 130, in extract_features\n    im_centered, global_pool=False, output_stride=16, is_training=False\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 274, in resnet_v1_50\n    scope=scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 207, in resnet_v1\n    net = resnet_utils.stack_blocks_dense(net, blocks, output_stride)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py\", line 211, in stack_blocks_dense\n    net = block.unit_fn(net, rate=rate, **dict(unit, stride=1))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 121, in bottleneck\n    residual, depth, [1, 1], stride=1, activation_fn=None, scope='conv3')\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1058, in convolution\n    outputs = normalizer_fn(outputs, **normalizer_params)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 650, in batch_norm\n    outputs = layer.apply(inputs, training=is_training)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\", line 717, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/normalization.py\", line 501, in call\n    outputs = self._fused_batch_norm(inputs, training=training)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/normalization.py\", line 396, in _fused_batch_norm\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py\", line 56, in smart_cond\n    return false_fn()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/normalization.py\", line 393, in _fused_batch_norm_inference\n    data_format=self._data_format)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py\", line 904, in fused_batch_norm\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 3429, in _fused_batch_norm\n    is_training=is_training, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,77,96,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.001e-05, is_training=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_549 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1054_...ims/concat\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,77,96,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.001e-05, is_training=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_549 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1054_...ims/concat\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f4f41de2dea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinux_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# deeplabcut.train_network(config_path,shuffle=1,trainingsetindex=0,gputouse=None,max_snapshots_to_keep=5,autotune=False,displayiters=100,saveiters=15000, maxiters=30000)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights, modelprefix)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m             )  # pass on path and file name for pose_cfg.yaml!\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    253\u001b[0m         [_, loss_val, summary] = sess.run(\n\u001b[1;32m    254\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_summaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcurrent_lr\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[1,77,96,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.001e-05, is_training=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_549 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1054_...ims/concat\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm', defined at:\n  File \"/usr/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-5-f4f41de2dea4>\", line 1, in <module>\n    deeplabcut.train_network(linux_config_file)\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/training.py\", line 189, in train_network\n    allow_growth=allow_growth,\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/train.py\", line 174, in train\n    losses = pose_net(cfg).train(batch)\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py\", line 279, in train\n    heads = self.get_net(batch[Batch.inputs])\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py\", line 178, in get_net\n    net, end_points = self.extract_features(inputs)\n  File \"/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/nnet/pose_net.py\", line 130, in extract_features\n    im_centered, global_pool=False, output_stride=16, is_training=False\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 274, in resnet_v1_50\n    scope=scope)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 207, in resnet_v1\n    net = resnet_utils.stack_blocks_dense(net, blocks, output_stride)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_utils.py\", line 211, in stack_blocks_dense\n    net = block.unit_fn(net, rate=rate, **dict(unit, stride=1))\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/slim/python/slim/nets/resnet_v1.py\", line 121, in bottleneck\n    residual, depth, [1, 1], stride=1, activation_fn=None, scope='conv3')\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 1058, in convolution\n    outputs = normalizer_fn(outputs, **normalizer_params)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py\", line 650, in batch_norm\n    outputs = layer.apply(inputs, training=is_training)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/base.py\", line 717, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/normalization.py\", line 501, in call\n    outputs = self._fused_batch_norm(inputs, training=training)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/normalization.py\", line 396, in _fused_batch_norm\n    training, _fused_batch_norm_training, _fused_batch_norm_inference)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/utils.py\", line 206, in smart_cond\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py\", line 56, in smart_cond\n    return false_fn()\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/layers/normalization.py\", line 393, in _fused_batch_norm_inference\n    data_format=self._data_format)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py\", line 904, in fused_batch_norm\n    name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\", line 3429, in _fused_batch_norm\n    is_training=is_training, name=name)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[1,77,96,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/FusedBatchNorm = FusedBatchNorm[T=DT_FLOAT, data_format=\"NHWC\", epsilon=1.001e-05, is_training=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/Conv2D, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_mean/read, resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm/moving_variance/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: absolute_difference/weighted_loss/assert_broadcastable/is_valid_shape/has_valid_nonscalar_shape/has_invalid_dims/concat/_549 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_1054_...ims/concat\", tensor_type=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(linux_config_file)\n",
    "# deeplabcut.train_network(config_path,shuffle=1,trainingsetindex=0,gputouse=None,max_snapshots_to_keep=5,autotune=False,displayiters=100,saveiters=15000, maxiters=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#deeplabcut.evaluate_network(path_config_file,Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a for loop or something for the four functions below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#video_folder = '/home/qdf0761/DeepLabCut/projects/Han_20201120/'\n",
    "#videos = [video_folder + 'Han_20201120_setup1_cam1.avi',\n",
    "#          video_folder + 'Han_20201120_setup1_cam2.avi',\n",
    "#          video_folder + 'Han_20201120_setup1_cam3.avi',\n",
    "#          video_folder + 'Han_20201120_setup1_cam4.avi',\n",
    "#          video_folder + 'Han_20201120_setup2_cam1.avi',\n",
    "#          video_folder + 'Han_20201120_setup2_cam2.avi',\n",
    "#          video_folder + 'Han_20201120_setup2_cam3.avi',\n",
    "#          video_folder + 'Han_20201120_setup2_cam4.avi',\n",
    "#          video_folder + 'Han_20201120_setup3_cam1.avi',\n",
    "#          video_folder + 'Han_20201120_setup3_cam2.avi',\n",
    "#          video_folder + 'Han_20201120_setup3_cam3.avi',\n",
    "#          video_folder + 'Han_20201120_setup3_cam4.avi',\n",
    "#          video_folder + 'Han_20201120_setup4_cam1.avi',\n",
    "#          video_folder + 'Han_20201120_setup4_cam2.avi',\n",
    "#          video_folder + 'Han_20201120_setup4_cam3.avi',\n",
    "#          video_folder + 'Han_20201120_setup4_cam4.avi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0]],\n",
      " 'all_joints_names': ['objectA'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TestNov23/Test_Qiwei95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/qdf0761/DeepLabCut/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_TestNov23/Documentation_data-Test_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/dlc-models/iteration-0/TestNov23-trainset95shuffle1/test/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-1030000 for model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/dlc-models/iteration-0/TestNov23-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/dlc-models/iteration-0/TestNov23-trainset95shuffle1/train/snapshot-1030000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1812 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi\n",
      "Duration of video [s]:  72.48 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1812  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1818it [01:45, 16.02it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1813 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi\n",
      "Duration of video [s]:  95.42 , recorded with  19.0 fps!\n",
      "Overall # of frames:  1813  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1818it [01:45, 16.54it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi\n",
      "Duration of video [s]:  78.64 , recorded with  22.0 fps!\n",
      "Overall # of frames:  1730  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1734it [01:36, 18.26it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1730 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi\n",
      "Duration of video [s]:  78.64 , recorded with  22.0 fps!\n",
      "Overall # of frames:  1730  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1734it [01:37, 18.18it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1550 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi\n",
      "Duration of video [s]:  62.0 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1550  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1560it [01:28, 16.86it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1551 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi\n",
      "Duration of video [s]:  103.4 , recorded with  15.0 fps!\n",
      "Overall # of frames:  1551  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1560it [01:28, 16.89it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1925 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi\n",
      "Duration of video [s]:  77.0 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1925  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1938it [01:48, 18.63it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1935 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi\n",
      "Duration of video [s]:  120.94 , recorded with  16.0 fps!\n",
      "Overall # of frames:  1935  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1938it [01:48, 18.63it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi\n",
      "Duration of video [s]:  53.08 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1327  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1339it [01:15, 18.77it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "  0%|          | 0/1327 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "Starting to analyze %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi\n",
      "Duration of video [s]:  53.08 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1327  found with (before cropping) frame dimensions:  1280 1024\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1339it [01:15, 18.75it/s]                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  1327\n",
      "Saving results in /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos...\n",
      "Saving csv poses!\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DLC_resnet50_TestNov23shuffle1_1030000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#deeplabcut.analyze_videos(path_config_file,[r'C:\\Users\\dongq\\DLC\\Han-Qiwei-2020-07-02\\videos\\exp00001.avi'], save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,[r'C:\\Users\\dongq\\DLC\\Han-Qiwei-2020-07-02\\videos\\exp00002.avi'], save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,[r'C:\\Users\\dongq\\DLC\\Han-Qiwei-2020-07-02\\videos\\exp00003.avi'], save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,[r'C:\\Users\\dongq\\DLC\\Han-Qiwei-2020-07-02\\videos\\exp00004.avi'], save_as_csv=True)\n",
    "\n",
    "\n",
    "#deeplabcut.analyze_videos(path_config_file,['/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-08-04-FreeReaching/videos/exp00001.avi'], save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,['/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-08-04-FreeReaching/videos/exp00002.avi'], save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,['/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-08-04-FreeReaching/videos/exp00003.avi'], save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,['/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-08-04-FreeReaching/videos/exp00004.avi'], save_as_csv=True)\n",
    "\n",
    "deeplabcut.analyze_videos(path_config_file,videos, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,vid2, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,vid3, save_as_csv=True)\n",
    "#deeplabcut.analyze_videos(path_config_file,vid4, save_as_csv=True)\n",
    "\n",
    "\n",
    "#deeplabcut.analyze_videos(config_path,videos,videotype='avi',shuffle=1,trainingsetindex=0,gputouse=None,save_as_csv=False, destfolder=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 209.34it/s]\n",
      "1it [00:00, 223.32it/s]\n",
      "1it [00:00, 219.71it/s]\n",
      "1it [00:00, 219.34it/s]\n",
      "1it [00:00, 211.91it/s]\n",
      "1it [00:00, 214.77it/s]\n",
      "1it [00:00, 217.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1it [00:00, 221.08it/s]\n",
      "1it [00:00, 242.89it/s]\n",
      "1it [00:00, 245.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi\n",
      "Saving filtered csv poses!\n",
      "Filtering with spline model /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi\n",
      "Saving filtered csv poses!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#deeplabcut.filterpredictions?\n",
    "#deeplabcut.filterpredictions(path_config_file,[r'/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-21/videos/exp00001.avi'], shuffle=1)\n",
    "\n",
    "deeplabcut.filterpredictions(path_config_file,videos,filtertype='spline')\n",
    "#deeplabcut.filterpredictions(path_config_file,vid2,filtertype='spline')\n",
    "#deeplabcut.filterpredictions(path_config_file,vid3,filtertype='spline')\n",
    "#deeplabcut.filterpredictions(path_config_file,vid4,filtertype='spline')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi\n",
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi and data.\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos  already exists!\n",
      "/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/plot-poses  already exists!\n",
      "Plots created! Please check the directory \"plot-poses\" within the video directory\n"
     ]
    }
   ],
   "source": [
    "#linux\n",
    "#deeplabcut.plot_trajectories(path_config_file,[r'/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-21/videos/exp00001.avi'])\n",
    "#deeplabcut.plot_trajectories(path_config_file,[r'/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-21/videos/exp00002.avi'])\n",
    "#deeplabcut.plot_trajectories(path_config_file,[r'/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-21/videos/exp00003.avi'])\n",
    "\n",
    "#Windows\n",
    "deeplabcut.plot_trajectories(path_config_file,videos)\n",
    "#deeplabcut.plot_trajectories(path_config_file,vid2)\n",
    "#deeplabcut.plot_trajectories(path_config_file,vid3)\n",
    "#deeplabcut.plot_trajectories(path_config_file,vid4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/1812 [00:00<00:17, 105.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi and data.\n",
      "1812\n",
      "Duration of video [s]:  72.48 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1812 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1812/1812 [00:16<00:00, 108.22it/s]\n",
      "  1%|          | 10/1813 [00:00<00:18, 94.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi and data.\n",
      "1813\n",
      "Duration of video [s]:  95.42 , recorded with  19.0 fps!\n",
      "Overall # of frames:  1813 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1813/1813 [00:17<00:00, 105.17it/s]\n",
      "  1%|          | 11/1730 [00:00<00:16, 103.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi and data.\n",
      "1730\n",
      "Duration of video [s]:  78.64 , recorded with  22.0 fps!\n",
      "Overall # of frames:  1730 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1730/1730 [00:15<00:00, 113.27it/s]\n",
      "  1%|          | 11/1730 [00:00<00:17, 101.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi and data.\n",
      "1730\n",
      "Duration of video [s]:  78.64 , recorded with  22.0 fps!\n",
      "Overall # of frames:  1730 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1730/1730 [00:16<00:00, 107.74it/s]\n",
      "  1%|          | 10/1550 [00:00<00:16, 93.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi and data.\n",
      "1550\n",
      "Duration of video [s]:  62.0 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1550 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1550/1550 [00:14<00:00, 110.33it/s]\n",
      "  1%|          | 9/1551 [00:00<00:18, 83.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi and data.\n",
      "1551\n",
      "Duration of video [s]:  103.4 , recorded with  15.0 fps!\n",
      "Overall # of frames:  1551 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1551/1551 [00:14<00:00, 106.76it/s]\n",
      "  1%|          | 11/1925 [00:00<00:18, 101.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi and data.\n",
      "1925\n",
      "Duration of video [s]:  77.0 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1925 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1925/1925 [00:18<00:00, 105.81it/s]\n",
      "  1%|          | 10/1935 [00:00<00:20, 93.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi and data.\n",
      "1935\n",
      "Duration of video [s]:  120.94 , recorded with  16.0 fps!\n",
      "Overall # of frames:  1935 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1935/1935 [00:18<00:00, 105.75it/s]\n",
      "  1%|          | 11/1327 [00:00<00:12, 103.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi and data.\n",
      "1327\n",
      "Duration of video [s]:  53.08 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1327 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1327/1327 [00:12<00:00, 110.37it/s]\n",
      "  1%|          | 10/1327 [00:00<00:13, 97.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos ['/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_6in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_7in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_9_5in00002.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00001.avi', '/home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi']\n",
      "Loading  /home/qdf0761/DeepLabCut/projects/Test-Qiwei-2020-11-23/videos/Han_20201123_test_15in00002.avi and data.\n",
      "1327\n",
      "Duration of video [s]:  53.08 , recorded with  25.0 fps!\n",
      "Overall # of frames:  1327 with cropped frame dimensions:  1280 1024\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1327/1327 [00:12<00:00, 103.11it/s]\n"
     ]
    }
   ],
   "source": [
    "#deeplabcut.create_labeled_video(path_config_file,['/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-14-1/videos/exp00015.avi'])\n",
    "deeplabcut.create_labeled_video(path_config_file,videos,filtered=True)\n",
    "#deeplabcut.create_labeled_video(path_config_file,vid2,filtered=True)\n",
    "#deeplabcut.create_labeled_video(path_config_file,vid3,filtered=True)\n",
    "#deeplabcut.create_labeled_video(path_config_file,vid4,filtered=True)\n",
    "\n",
    "###TODO: ADD PRINT STATEMENTS IN MAKE_LABELED_VIDEO.PY's create_labeled_video() and CreateVideo() FUNCTIONS, SEE IF ANY PROBLEMS ARE IN THERE\n",
    "#make_labeled_video.py, around line 397, print(\"here\")\n",
    "#                              line 50, print(\"In CreateVideo()\")\n",
    "#                              line 115,print(\"end of CreateVideo()\")\n",
    "#                              line 125,print(\"In CreateVideoSlow()\")\n",
    "#                              line 248,print(\"End Of CreateVideoSlow()\")\n",
    "#DeepLabCut/deeplabcut/utils/make_labeled_video.py\n",
    "\n",
    "#deeplabcut.create_labeled_video(path_config_file,[r'/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-14-1/videos/exp00016.avi'])\n",
    "#deeplabcut.create_labeled_video(path_config_file,[r'/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-02-14-1/videos/exp00017.avi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/deeplabcut/utils/make_labeled_video.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import os\n",
    "#import inspect\n",
    "#import external_def\n",
    "\n",
    "\n",
    "#print(os.path.abspath(inspect.getfile(deeplabcut.create_labeled_video)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['shoulder1',\n",
      "                      'arm1',\n",
      "                      'arm2',\n",
      "                      'elbow1',\n",
      "                      'elbow2',\n",
      "                      'wrist1',\n",
      "                      'wrist2',\n",
      "                      'hand1',\n",
      "                      'hand2',\n",
      "                      'hand3'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_HanJul2\\\\Han_Qiwei95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'D:\\\\Anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_HanJul2\\\\Documentation_data-Han_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\dongq\\\\DLC\\\\Han-Qiwei-2020-07-02',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/qdf0761/DeepLabCut/projects/Han-Qiwei-2020-08-04-FreeReaching/dlc-models/iteration-0/HanAug4-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching batchsize to 1, as default/tensorpack/deterministic loaders do not support batches >1. Use imgaug loader.\n",
      "Starting with standard pose-dataset loader.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\dongq\\\\DLC\\\\Han-Qiwei-2020-07-02/training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_HanJul2\\\\Han_Qiwei95shuffle1.mat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dongq\\\\DLC\\\\Han-Qiwei-2020-07-02/training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_HanJul2\\\\Han_Qiwei95shuffle1.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1e1eaa16969d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Try to retrain the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(config, shuffle, trainingsetindex, max_snapshots_to_keep, displayiters, saveiters, maxiters, allow_growth, gputouse, autotune, keepdeconvweights)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgputouse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdeconvweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_growth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep, keepdeconvweights, allow_growth)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;31m#in case this was edited for analysis.-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0mbatch_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menqueue_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaceholders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup_preloading\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/dataset/factory.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mdeeplabcut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_estimation_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_defaultdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoseDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPoseDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'deterministic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting with deterministic pose-dataset loader.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/dataset/pose_defaultdataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeplabcut/pose_estimation_tensorflow/dataset/pose_defaultdataset.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# Load Matlab file dataset annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mmlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mmlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \"\"\"\n\u001b[1;32m    140\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmdict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mmat_reader_factory\u001b[0;34m(file_name, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mbyte_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_opened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mmjv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_matfile_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmjv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mappendmat\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfile_like\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'.mat'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\dongq\\\\DLC\\\\Han-Qiwei-2020-07-02/training-datasets\\\\iteration-0\\\\UnaugmentedDataSet_HanJul2\\\\Han_Qiwei95shuffle1.mat'"
     ]
    }
   ],
   "source": [
    "#Try to retrain the dataset\n",
    "\n",
    "#deeplabcut.train_network(path_config_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "693px",
    "left": "1337.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
