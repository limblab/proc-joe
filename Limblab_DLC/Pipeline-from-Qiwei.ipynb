{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:521: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:522: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "On Shrek Docker Only\n",
    "\"\"\"\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import sys\n",
    "from ruamel.yaml import YAML\n",
    "import yaml\n",
    "os.environ[\"DLClight\"]=\"True\"\n",
    "import deeplabcut\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'Han_202012'\n",
    "experimenter = 'Joe'\n",
    "video_project_folder = '/home/jts3256/DLC_videos/Han_202012-Joe-2020-12-04'\n",
    "path_config_file = video_project_folder + '/config.yaml'\n",
    "linux_config_file = video_project_folder + '/config_linux.yaml'\n",
    "shutil.copyfile(path_config_file,linux_config_file)\n",
    "\n",
    "# convert config file to a linux friendly version\n",
    "with open(path_config_file) as file:\n",
    "    orig_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "# change project_path to video_main_folder\n",
    "orig_config['project_path'] = video_project_folder\n",
    "\n",
    "# change video_sets\n",
    "# so we need to build a new dictionary with the video filenames as keys and the crop as entries\n",
    "videos = glob.glob(video_project_folder + r'/videos/*.avi')\n",
    "x=orig_config['video_sets']\n",
    "x_keys = list(x.keys())\n",
    "video_dict = {}\n",
    "for i in range(len(videos)):\n",
    "    video_dict[videos[i]] = x[x_keys[i]]\n",
    "    \n",
    "orig_config['video_sets'] = video_dict\n",
    "\n",
    "# save config as config_linux and point path_config_file to it\n",
    "with open(linux_config_file,'w') as file:\n",
    "    yaml.dump(orig_config,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It appears that the images were labeled on a Windows system, but you are currently trying to create a training set on a Unix system. \n",
      " In this case the paths should be converted. Do you want to proceed with the conversion?\n",
      "yes/noyes\n",
      "Annotation data converted to unix format...\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([ 8, 12,  1, 61, 11,  9, 29, 21, 38, 20, 48, 23, 40, 28, 34,  4, 54,\n",
       "          39, 33, 22, 59, 63, 55, 51,  0, 49, 58, 62, 24, 17, 41, 15, 27,  6,\n",
       "          18,  5, 32, 35, 26, 44, 10, 37, 25, 47,  7, 13, 60, 52, 43, 53, 19,\n",
       "          46, 30, 31, 16, 42, 50, 36,  3, 57]), array([14, 45,  2, 56])))]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deeplabcut.create_training_dataset(linux_config_file,userfeedback=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0],\n",
      "                [1],\n",
      "                [2],\n",
      "                [3],\n",
      "                [4],\n",
      "                [5],\n",
      "                [6],\n",
      "                [7],\n",
      "                [8],\n",
      "                [9],\n",
      "                [10],\n",
      "                [11],\n",
      "                [12]],\n",
      " 'all_joints_names': ['shoulder',\n",
      "                      'arm1',\n",
      "                      'arm2',\n",
      "                      'elbow1',\n",
      "                      'elbow2',\n",
      "                      'wrist1',\n",
      "                      'wrist2',\n",
      "                      'hand1',\n",
      "                      'hand2',\n",
      "                      'hand3',\n",
      "                      'pointX',\n",
      "                      'pointY',\n",
      "                      'pointZ'],\n",
      " 'batch_size': 1,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Han_202012Dec4/Han_202012_Joe95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': '/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Han_202012Dec4/Documentation_data-Han_202012_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 13,\n",
      " 'optimizer': 'sgd',\n",
      " 'pairwise_huber_loss': False,\n",
      " 'pairwise_predict': False,\n",
      " 'partaffinityfield_predict': False,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': '/home/jts3256/DLC_videos/Han_202012-Joe-2020-12-04',\n",
      " 'regularize': False,\n",
      " 'rotation': 25,\n",
      " 'rotratio': 0.4,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': '/home/jts3256/DLC_videos/Han_202012-Joe-2020-12-04/dlc-models/iteration-0/Han_202012Dec4-trainset95shuffle1/train/snapshot',\n",
      " 'stride': 8.0,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting single-animal trainer\n",
      "Starting with imgaug pose-dataset loader (=default).\n",
      "Batch Size is 1\n",
      "Initializing ResNet\n",
      "Loading ImageNet-pretrained resnet_50\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': '/home/jts3256/DLC_videos/Han_202012-Joe-2020-12-04/dlc-models/iteration-0/Han_202012Dec4-trainset95shuffle1/train/snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'crop_pad': 0, 'scoremap_dir': 'test', 'batch_size': 1, 'dataset_type': 'default', 'deterministic': False, 'mirror': False, 'pairwise_huber_loss': False, 'weigh_only_present_joints': False, 'partaffinityfield_predict': False, 'pairwise_predict': False, 'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12]], 'all_joints_names': ['shoulder', 'arm1', 'arm2', 'elbow1', 'elbow2', 'wrist1', 'wrist2', 'hand1', 'hand2', 'hand3', 'pointX', 'pointY', 'pointZ'], 'cropratio': 0.4, 'dataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Han_202012Dec4/Han_202012_Joe95shuffle1.mat', 'display_iters': 1000, 'init_weights': '/home/jts3256/.local/lib/python3.6/site-packages/deeplabcut/pose_estimation_tensorflow/models/pretrained/resnet_v1_50.ckpt', 'max_input_size': 1500, 'metadataset': 'training-datasets/iteration-0/UnaugmentedDataSet_Han_202012Dec4/Documentation_data-Han_202012_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'net_type': 'resnet_50', 'num_joints': 13, 'pos_dist_thresh': 17, 'project_path': '/home/jts3256/DLC_videos/Han_202012-Joe-2020-12-04', 'rotation': 25, 'rotratio': 0.4, 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25, 'covering': True, 'elastic_transform': True, 'motion_blur': True, 'motion_blur_params': {'k': 7, 'angle': [-90, 90]}}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000 loss: 0.0269 lr: 0.005\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(linux_config_file)\n",
    "# deeplabcut.train_network(config_path,shuffle=1,trainingsetindex=0,gputouse=None,max_snapshots_to_keep=5,autotune=False,displayiters=100,saveiters=15000, maxiters=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(linux_config_file,videos, save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.filterpredictions(linux_config_file,videos,filtertype='spline')\n",
    "deeplabcut.plot_trajectories(linux_config_file,videos)\n",
    "deeplabcut.create_labeled_video(path_config_file,videos,filtered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move files from Shrek to server\n",
    "\n",
    "server_folder_loc = \"/mnt/L_MillerLab/data/\"\n",
    "shrek_folder_loc = video_project_folder + \"/training-datasets/\"\n",
    "\n",
    "cp_command = \"cp -r \" + shrek_folder_loc + \" \" + server_folder_loc\n",
    "\n",
    "shutil.copytree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp_command"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "693px",
    "left": "1337.33px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
